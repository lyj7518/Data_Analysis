---
title: "Assignment4"
author: "20192246 이유진"
date: "2023-05-05"
output: 
  html_document: 
    fig_height: 6
    fig_width: 10
    highlight: pygments
    toc: yes
    toc_depth: 2
    toc_float: yes
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 문제1
___
data preprocessing 진행
```{r message=FALSE}
# 필요 라이브러리 불러오기
library(rsample)
library(ROCR) 
library(e1071)
library(kernlab)
library(ggplot2)
library(psych)
library(glmnet)
library(caret)
library(e1071)
```

```{r}
# 데이터 불러오기
data = read.csv("C:/Users/이유진/Downloads/FlightRecords.csv")
```

```{r}
# 7개의 변수로 데이터프레임 구성
data = data[, c(10, 3, 8, 4, 2, 9, 13)]
str(data)
```

### 1.1 deptime 필터링
```{r}
data = subset(data, deptime>=600 & deptime<2200)
```
- 다음과 같이 오전 6시부터 오후 22시까지의 데이터만 추출한다.

### 1.2 deptime factor형으로 형변환
```{r}
data$deptime = as.factor(floor(data$deptime / 100))
```
- deptime 변수의 값을 100으로 나누고 정수값으로 내려서 범주형 변수로 변환한다.

### 1.3 dayweek, weather factor형으로 형변환
```{r}
data$dayweek = as.factor(data$dayweek)
data$weather = as.factor(data$weather)
```
- as.factor 함수를 사용하여 dayweek, weather 변수를 범주형 변수로 변환한다.

### 1.4 delay 변수의 level 순서 변경
```{r}
data$delay = factor(data$delay, levels=c("ontime", "delayed"))
levels(data$delay)
```
- delay 변수를 "ontime", "delayed" 범주를 가지는 범주형 변수로 변환한다.


## 문제2
___
각각의 변수에 따른 연착 비율 시각화

### 2.1 요일 별 연착 비율
```{r}
ggplot(data, aes(x = dayweek, fill = delay)) + geom_bar(position = "fill")
```

- 월요일(1), 일요일(7)의 연착 비율이 상대적으로 높으며, 토요일의 연착 비율이 가장 낮은 것을 알 수 있다.

### 2.2 출발 시간대 별 연착 비율
```{r}
ggplot(data, aes(x = deptime, fill = delay)) + geom_bar(position = "fill")
```

- 19시 출발 비행기의 연착 비율이 가장 높다.

### 2.3 출발 공항 별 연착 비율
```{r}
ggplot(data, aes(x = origin, fill = delay)) + geom_bar(position = "fill")
```

- BWI, IAD 공항의 연착 비율은 비슷하고, DCA 공항의 연착 비율은 두 공항에 비해 상대적 낮은 것을 알 수 있다.

### 2.4 도착 공항 별 연착 비율
```{r}
ggplot(data, aes(x = dest, fill = delay)) + geom_bar(position = "fill")
```

- LGA 공항의 연착 비율은 두 공항에 비해 상대적 낮다.

### 2.5 항공사 별 연착비율
```{r}
ggplot(data, aes(x = carrier, fill = delay)) + geom_bar(position = "fill")
```

-  MQ 항공사의 연착 비율이 가장 높으며, DL 항공사의 연착 비율이 가장 낮다.

### 2.6 날씨 별 연착 비율
```{r}
ggplot(data, aes(x = weather, fill = delay)) + geom_bar(position = "fill")
```

- 날씨가 나쁠 때 연착 비율이 100%인 것을 확인할 수 있다.


## 문제3
___
7개의 모든 변수들 간의 상관관계를 시각화

```{r}
pairs.panels(data)
```

- 다음과 같이 변수들 간의 상관관계를 시각화한 결과, 변수 간 **유의한 상관관계는 관찰되지 않는다.**  따라서 다중공선성 문제가 발생할 확률이 낮다.


## 문제4
___
train / test set 분할

```{r}
# 데이터셋을 70:30 비율로 training set과 test set으로 분할
set.seed(42)
split = initial_split(data, prop=0.7, strata = "delay")
train = training(split)
test = testing(split)
table(train$delay)
table(test$delay)
```

- 다음과 같이 strata = "delay"로 설정 후 train/test 데이터셋을 분리하였다.
- 두 데이터셋 모두 ontime : delayed = 1 : 0.23의 비율로 delay 변수의 분포가 큰 차이 없이 고르게 분할된 것을 확인할 수 있다.


## 문제5
___
Baseline Model 수립

```{r}
# weather = 1 일 때 delayed로 예측하는 모델
pred_base = factor(sign(ifelse(train$weather == 1, 1, 0)), 
               levels=c(0, 1), labels=c("ontime", "delayed"))

confusionMatrix(pred_base, train$delay, positive="delayed")
```

- 다음과 같이 weather = 1("Bad") 일 때 delayed로 예측하는 단순한 Baseline Model을 구축하였다.
- 그 결과, Baseline 모델은 training set에 대해서 약 82.7%의 Accuracy를 가진다.
- 하지만 민감도는 약 8.7%로 실제 지연된 항공기를 지연으로 예측할 확률이 매우 낮음을 알 수 있다.


## 문제6
___
Logistic Regression Model 수립

```{r}
# logistic regression model 수립
model1 = glm(delay~., data=train, family="binomial")
summary(model1) 
```

### 6.1
- deptime19의 regression coefficient 추정값 = **2.36957**
- 해석 : deptime6에 비해 delay될 오즈비가 2.36957배 높다.

### 6.2
```{r}
# 예측을 위한 새로운 데이터 생성 
new_data = data.frame(dayweek = "4", deptime = "15", origin = "IAD", dest = "EWR", carrier = "DL", weather = "0")

# new data 예측
prob_delay = predict(model1, newdata = new_data, type = "response")
print(prob_delay)
```

- 날씨에 문제가 없는 목요일 15시에 IAD에서 출발하여 EWR로 도착한 Delta 항공기가 연착될 확률은 약 **25%**이다.

### 6.3
```{r}
# threshold = 0.3
prob = predict(model1, train, type = "response")

pred1 = rep("ontime", 1511)
pred1[prob > 0.3] = "delayed"
confusionMatrix(factor(pred1), train$delay, positive = "delayed") 
```

```{r}
# threshold = 0.5
pred2 = rep("ontime", 1511)
pred2[prob > 0.5] = "delayed"
confusionMatrix(factor(pred2), train$delay, positive = "delayed") 
```

```{r}
# threshold = 0.7
pred3 = rep("ontime", 1511)
pred3[prob > 0.7] = "delayed"
confusionMatrix(factor(pred3), train$delay, positive = "delayed") 
```

- k = 0.3 일 때 Accuracy : 0.8114
- k = 0.5 일 때 Accuracy : 0.8465
- k = 0.7 일 때 Accuracy : 0.8279
- k = 0.5에서 가장 높은 정확도를 보이는 것을 확인할 수 있다.

### 6.4
- Baseline 모델은 training set에 대해서 약 82.7%의 Accuracy를 가졌다. Accuracy 값을 비교할 때는 k=0.5에서의 logistic regression model의 성능이 베이스라인 모델보다 높다고 할 수 있다. 
- 또한 민감도를 비교해보았을 때도 logistic regression model의 성능이 (k = 0.3, 0.5, 0.7에서) 높은 것을 확인할 수 있다.


## 문제7
___
Lasso regression 적용

### 7.1
```{r}
# train set을 대상으로 Lasso regression 적용
trainX = model.matrix(delay~., data=train)[,-1]
trainY = train$delay
cv_lasso = cv.glmnet(x = trainX, y = trainY, alpha = 1, family = "binomial", type.measure = "class", nfolds = 10)
plot(cv_lasso)
```

```{r}
# misclassification error 변화 확인 
cv_lasso$cvm
```

- misclassification error값이 0.17보다 낮아지는 25번째 모델 선택

```{r}
# 회귀계수 확인
lambda = cv_lasso$lambda[25]
coef(cv_lasso, s = lambda)
```

- 최종적으로 모델에 포함된 변수는 총 14개이다.
- dayweek2, dayweek6, dayweek7, deptime8, deptime12, deptime13, deptime14, deptime15, deptime19, originDCA, carrierDL, carrierMQ, carrierUS, weather1 변수가 포함되었다.


### 7.2
#### train set
```{r}
# train set에 대한 각 모델의 ROC Curve
prob_test = predict(model1, newdata = train, type = "response")
prob_lasso = predict(cv_lasso, newx = model.matrix(delay~., data=train)[,-1], s = lambda, type = "response")

predict_logistic = prediction(prob_test, train$delay, c("ontime", "delayed"))
performance_logistic = performance(predict_logistic, measure = "tpr", x.measure = "fpr")

predict_lasso = prediction(prob_lasso, train$delay, c("ontime", "delayed"))
performance_lasso = performance(predict_lasso, measure = "tpr", x.measure = "fpr")

plot(performance_logistic, col="darkred", lwd=3)
plot(performance_lasso, col="darkblue", lwd=3,, add = TRUE)
```

```{r}
# AUC값 출력_logistic regression model
auc_logistic <- performance(predict_logistic, measure = "auc")
auc_logistic@y.values[[1]]
```

```{r}
# AUC값 출력_lasso regression model
auc_lasso <- performance(predict_lasso, measure = "auc")
auc_lasso@y.values[[1]]
```

- training set에서 각 모델의 AUC 값을 비교한 결과, lasso를 적용하지 않은 기본 logistic regression model의 성능이 더 높다. 즉, lasso regression의 효과가 있다고 보기는 어렵다.

#### test set
```{r}
# train set에 대한 각 모델의 ROC Curve
prob_test_2 = predict(model1, newdata = test, type = "response")
prob_lasso_2 = predict(cv_lasso, newx = model.matrix(delay~., data=test)[,-1], s = lambda, type = "response")

predict_logistic_2 = prediction(prob_test_2, test$delay, c("ontime", "delayed"))
performance_logistic_2 = performance(predict_logistic_2, measure = "tpr", x.measure = "fpr")

predict_lasso_2 = prediction(prob_lasso_2, test$delay, c("ontime", "delayed"))
performance_lasso_2 = performance(predict_lasso_2, measure = "tpr", x.measure = "fpr")

plot(performance_logistic_2, col="darkred", lwd=3)
plot(performance_lasso_2, col="darkblue", lwd=3,, add = TRUE)
```

```{r}
# AUC값 출력_logistic regression model
auc_logistic_2 <- performance(predict_logistic_2, measure = "auc")
auc_logistic_2@y.values[[1]]
```

```{r}
# AUC값 출력_lasso regression model
auc_lasso_2 <- performance(predict_lasso_2, measure = "auc")
auc_lasso_2@y.values[[1]]
```

- test set에서도 역시 lasso를 적용하지 않은 기본 logistic regression model의 성능이 더 높다. 즉, lasso regression의 효과가 있다고 보기는 어렵다.


## 문제8
___
k-nn 적용

```{r}
# knn fitting
knn_fit = train(data=train, delay~., method="knn", 
                trControl = trainControl(method="repeatedcv", number = 5, repeats = 5),
                tuneGrid = expand.grid(k = seq(1, 50, 2)))

knn_fit

ggplot(knn_fit) + theme_bw()
```

- 다음과 같이 5-fold cross validation을 5회 반복한 결과, **k = 5에서 Accuracy = 0.8214438**로 가장 높은 성능을 보인다.


## 문제9
___
SVM 적용

```{r}
# svm fitting
set.seed(42)
tune.out = tune(svm, delay~., data=train, kernel="radial",
                 ranges=list(cost=c(0.01, 0.1, 1, 10, 100, 1000),
                             gamma=c(0.01, 0.1, 1, 10, 100)))
summary(tune.out)
```

- cost = 10, gamma = 0.1에서 error가 0.1442663로 최소가 된다. 따라서 약 85%의 Accuracy를 가진다.


## 문제10
___
logistic regression, k-nn, svm model의 test set 성능 비교

### 1. logistic regression
```{r}
prob_logistic = predict(model1, newdata = test, type = "response")
pred_logistic = rep("ontime", nrow(test))
pred_logistic[prob_logistic > 0.5] = "delayed"
confusionMatrix(factor(pred_logistic), test$delay, positive = "delayed")

```

### 2. k-nn
```{r}
pred_knn = predict(knn_fit, newdata = test)
confusionMatrix(pred_knn, test$delay, positive = "delayed")
```


### 3. svm model
```{r}
pred_svm = predict(tune.out$best.model, newdata=test)
confusionMatrix(pred_svm, test$delay) 
```

- test set에 대한 Accuracy 성능은 다음과 같다.
  - logistic regression : **0.8395**
  - k-nn : **0.8179**
  - svm model : **0.8472**
- 즉, **svm model의 Accuracy 성능이 가장 높다**는 것을 확인할 수 있다. 하지만 Specificity는 약 0.3으로 낮은 값을 가진다.

